{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_and_Eval",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe6b856-eb83-44ba-e338-def5eff7cade"
      },
      "source": [
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# With a couple of ways to prevent RAM problems...\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq[:2500].to(device), test_mask[:2500].to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yemZq-3fEGnB"
      },
      "source": [
        "Get predictions and evaluate the model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41eecca-e5a0-4879-99eb-2321e5957fbd"
      },
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      1267\n",
            "           1       0.84      0.83      0.84      1233\n",
            "\n",
            "    accuracy                           0.84      2500\n",
            "   macro avg       0.84      0.84      0.84      2500\n",
            "weighted avg       0.84      0.84      0.84      2500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHIlNlG_Ebf3"
      },
      "source": [
        "Save the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpX1uTwjUPY6"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'original label': test_y, 'predicted label': preds, 'text': test_text})\n",
        "# Be careful with the encoding\n",
        "df.to_csv('results.csv',encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}